# ğŸ›¡ï¸ SPAM PROTECTION GUIDE - TRUYENHAYY.ONLINE

**NgÃ y:** November 7, 2025  
**Version:** 1.0

---

## âš ï¸ Táº I SAO Cáº¦N Báº¢O Vá»† CHá»NG SPAM?

### **Váº¥n Ä‘á»:**
- Spammers thÆ°á»ng dÃ¹ng search pages Ä‘á»ƒ inject spam links
- Pattern: `/tim-kiem?keyword=casino.com`, `/tim-kiem?keyword=http://spam.com`
- Google cÃ³ thá»ƒ index nhá»¯ng URLs nÃ y â†’ áº£nh hÆ°á»Ÿng SEO vÃ  reputation

### **Giáº£i phÃ¡p:**
**KHÃ”NG nÃªn dÃ¹ng robots.txt** Ä‘á»ƒ block spam search queries vÃ¬:
1. âŒ Google khÃ´ng há»— trá»£ wildcards phá»©c táº¡p
2. âŒ CÃ³ thá»ƒ block cáº£ search queries há»£p lá»‡
3. âŒ LÃ m file robots.txt quÃ¡ dÃ i

**NÃŠN dÃ¹ng:**
âœ… Meta tags `noindex` cho spam URLs
âœ… HTTP Headers `X-Robots-Tag: noindex`
âœ… Canonical tags
âœ… Server-side validation vÃ  blocking

---

## ğŸ”§ PHÆ¯Æ NG PHÃP Báº¢O Vá»† ÄÃšNG

### **1. robots.txt - CHá»ˆ block cÆ¡ báº£n** âœ…

**File hiá»‡n táº¡i Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u:**
```typescript
// src/app/robots.ts
export default function robots(): MetadataRoute.Robots {
  return {
    rules: [
      {
        userAgent: '*',
        allow: '/',
        disallow: [
          '/api/',           // Internal API
          '/_next/',         // Next.js internal
          '/admin/',         // Admin panel
          '/*?utm_',         // Tracking parameters
          '/*?fbclid=',      // Facebook tracking
          '/*?gclid=',       // Google tracking
          '/*?ref=',         // Referral tracking
        ],
      },
    ],
    sitemap: 'https://truyenhayy.online/sitemap.xml',
  }
}
```

**ÄÃºng chuáº©n Google:**
- âœ… Wildcards há»£p lá»‡ (chá»‰ á»Ÿ cuá»‘i)
- âœ… Block internal paths
- âœ… Block tracking parameters
- âœ… KhÃ´ng quÃ¡ phá»©c táº¡p

---

### **2. Next.js Middleware - Block spam requests** âœ…

**Táº¡o file:** `src/middleware.ts`

```typescript
import { NextResponse } from 'next/server'
import type { NextRequest } from 'next/server'

// Spam keywords to block
const SPAM_KEYWORDS = [
  'casino', 'slot', 'bet', 'telegram', 'sex', 'porn', 'xxx',
  'danhlo', 'danh-lo', 'daftar', 'binance', 'airdrop', 'scam'
]

// Spam TLDs to block
const SPAM_TLDS = ['.cc', '.vip', '.wink', '.live', '.xyz', '.top', '.club']

// SQL injection patterns
const SQL_PATTERNS = ['SELECT', 'UNION', 'DROP', 'DELETE', '<', '>', '{', '}', '[', ']']

export function middleware(request: NextRequest) {
  const { searchParams, pathname } = request.nextUrl

  // Only check search pages
  if (pathname === '/tim-kiem') {
    const keyword = searchParams.get('keyword')?.toLowerCase() || ''

    // Check for spam keywords
    const hasSpam = SPAM_KEYWORDS.some(spam => keyword.includes(spam))
    
    // Check for spam TLDs
    const hasTLD = SPAM_TLDS.some(tld => keyword.includes(tld))
    
    // Check for URLs
    const hasURL = keyword.includes('http') || keyword.includes('www.') || keyword.includes('//')
    
    // Check for SQL injection
    const hasSQL = SQL_PATTERNS.some(pattern => keyword.includes(pattern.toLowerCase()))

    // Block spam requests
    if (hasSpam || hasTLD || hasURL || hasSQL) {
      return NextResponse.redirect(new URL('/', request.url))
    }

    // Add noindex header for search pages (prevent Google indexing)
    const response = NextResponse.next()
    response.headers.set('X-Robots-Tag', 'noindex, nofollow')
    return response
  }

  return NextResponse.next()
}

// Configure which routes to run middleware on
export const config = {
  matcher: [
    '/tim-kiem',
    '/the-loai/:path*',
    '/danh-sach/:path*',
  ],
}
```

**Lá»£i Ã­ch:**
- âœ… Block spam **TRÆ¯á»šC KHI** render page
- âœ… Redirect spammers vá» homepage
- âœ… Add `noindex` header cho search pages
- âœ… KhÃ´ng áº£nh hÆ°á»Ÿng performance

---

### **3. Meta Tags - Prevent indexing search pages** âœ…

**Trong search page:** `src/app/tim-kiem/page.tsx`

```typescript
import type { Metadata } from 'next'

export async function generateMetadata({
  searchParams,
}: {
  searchParams: { keyword?: string }
}): Promise<Metadata> {
  const keyword = searchParams.keyword || ''

  return {
    title: `TÃ¬m kiáº¿m: ${keyword} | Truyenhayy.online`,
    description: `Káº¿t quáº£ tÃ¬m kiáº¿m cho "${keyword}"`,
    
    // IMPORTANT: Prevent search pages from being indexed
    robots: {
      index: false,        // Don't index
      follow: true,        // But follow links
      noarchive: true,     // Don't cache
      nosnippet: true,     // Don't show snippets
    },
  }
}
```

**Káº¿t quáº£ HTML:**
```html
<meta name="robots" content="noindex, follow, noarchive, nosnippet">
```

---

### **4. Canonical URLs - Consolidate duplicate content** âœ…

**Trong detail pages:** `src/app/truyen-tranh/[slug]/page.tsx`

```typescript
export async function generateMetadata({
  params,
}: {
  params: { slug: string }
}): Promise<Metadata> {
  const comic = await getComicDetail(params.slug)

  return {
    title: comic.name,
    description: comic.description,
    
    // Canonical URL (chÃ­nh thá»©c)
    alternates: {
      canonical: `https://truyenhayy.online/truyen-tranh/${params.slug}`,
    },
  }
}
```

---

### **5. Sitemap - Only include important pages** âœ…

**File:** `src/app/sitemap.ts`

```typescript
export default async function sitemap(): Promise<MetadataRoute.Sitemap> {
  const baseUrl = 'https://truyenhayy.online'

  return [
    {
      url: baseUrl,
      lastModified: new Date(),
      changeFrequency: 'daily',
      priority: 1,
    },
    // KHÃ”NG include search pages
    // KHÃ”NG include chapter pages (quÃ¡ nhiá»u)
    // CHá»ˆ include: homepage, genres, comic details
  ]
}
```

---

## ğŸ“Š SO SÃNH PHÆ¯Æ NG PHÃP

| PhÆ°Æ¡ng phÃ¡p | Hiá»‡u quáº£ | Performance | SEO Impact | Khuyáº¿n nghá»‹ |
|-------------|----------|-------------|------------|-------------|
| **robots.txt wildcard spam** | âŒ KhÃ´ng hoáº¡t Ä‘á»™ng | âœ… Tá»‘t | âš ï¸ CÃ³ thá»ƒ block nháº§m | âŒ KhÃ´ng nÃªn |
| **robots.txt simplified** | âœ… Tá»‘t (cÆ¡ báº£n) | âœ… Tá»‘t | âœ… An toÃ n | âœ… **NÃªn dÃ¹ng** |
| **Middleware blocking** | âœ… Ráº¥t tá»‘t | âœ… Tá»‘t | âœ… An toÃ n | âœ… **NÃªn dÃ¹ng** |
| **Meta robots noindex** | âœ… Ráº¥t tá»‘t | âœ… Tá»‘t | âœ… Tá»‘t nháº¥t | âœ… **NÃªn dÃ¹ng** |
| **Canonical URLs** | âœ… Tá»‘t | âœ… Tá»‘t | âœ… Tá»‘t | âœ… NÃªn dÃ¹ng |
| **Sitemap filtering** | âœ… Tá»‘t | âœ… Tá»‘t | âœ… Tá»‘t | âœ… NÃªn dÃ¹ng |

---

## ğŸ¯ KHUYáº¾N NGHá»Š TRIá»‚N KHAI

### **Æ¯U TIÃŠN CAO (Báº¯t buá»™c):**
1. âœ… **robots.txt simplified** - ÄÃƒ HOÃ€N THÃ€NH
2. âš ï¸ **Meta robots noindex** cho search pages - Cáº¦N THÃŠM
3. âš ï¸ **Middleware spam blocking** - Cáº¦N THÃŠM

### **Æ¯U TIÃŠN TRUNG BÃŒNH:**
4. âœ… Canonical URLs - ÄÃ£ cÃ³
5. âœ… Sitemap filtering - ÄÃ£ cÃ³

### **Æ¯U TIÃŠN THáº¤P (Optional):**
6. Rate limiting cho search
7. CAPTCHA cho search
8. User report spam

---

## ğŸ“ HÃ€NH Äá»˜NG TIáº¾P THEO

### **BÆ°á»›c 1: Táº¡o Middleware (5 phÃºt)**
```bash
# Táº¡o file
touch src/middleware.ts

# Copy code tá»« section 2 á»Ÿ trÃªn
# Customize spam keywords náº¿u cáº§n
```

### **BÆ°á»›c 2: Update Search Page Metadata (2 phÃºt)**
```typescript
// src/app/tim-kiem/page.tsx
export async function generateMetadata() {
  return {
    robots: {
      index: false,  // ADD THIS
      follow: true,
    },
  }
}
```

### **BÆ°á»›c 3: Test**
```bash
# Test search vá»›i spam keyword
curl http://localhost:3000/tim-kiem?keyword=casino

# Should redirect to homepage
# Or show blocked message
```

### **BÆ°á»›c 4: Monitor Google Search Console**
```
1. VÃ o Search Console
2. Check "Coverage" issues
3. Verify spam URLs khÃ´ng Ä‘Æ°á»£c index
4. Submit removal requests náº¿u cáº§n
```

---

## ğŸ” GOOGLE ROBOTS.TXT CHUáº¨N

### **âœ… ÄÃšNG:**
```
User-agent: *
Allow: /
Disallow: /api/
Disallow: /_next/
Disallow: /*?utm_
Disallow: /*?fbclid=

Sitemap: https://truyenhayy.online/sitemap.xml
```

### **âŒ SAI:**
```
User-agent: *
Disallow: /tim-kiem?keyword=*.com     # âŒ Wildcard á»Ÿ giá»¯a
Disallow: /*casino*                   # âŒ Wildcard 2 bÃªn
Disallow: /tim-kiem?keyword=*[*       # âŒ Pattern phá»©c táº¡p
```

**TÃ i liá»‡u tham kháº£o:**
- https://developers.google.com/search/docs/crawling-indexing/robots/create-robots-txt
- https://developers.google.com/search/docs/crawling-indexing/robots-txt-specifications

---

## ğŸ‰ Káº¾T LUáº¬N

### **robots.txt hiá»‡n táº¡i:**
âœ… **ÄÃƒ ÄÃšNG CHUáº¨N GOOGLE!**

**Äiá»ƒm máº¡nh:**
- âœ… Syntax Ä‘Ãºng
- âœ… Wildcards há»£p lá»‡
- âœ… KhÃ´ng quÃ¡ phá»©c táº¡p
- âœ… Block Ä‘Æ°á»£c tracking parameters
- âœ… Block Ä‘Æ°á»£c SEO scrapers

**Äá»ƒ báº£o vá»‡ tá»‘t hÆ¡n chá»‘ng spam:**
- âš ï¸ Cáº¦N thÃªm Middleware blocking
- âš ï¸ Cáº¦N thÃªm Meta robots noindex cho search pages

**Priority:**
1. Deploy vá»›i robots.txt hiá»‡n táº¡i (Ä‘Ã£ OK)
2. Sau Ä‘Ã³ thÃªm Middleware (tuáº§n sau cÅ©ng Ä‘Æ°á»£c)

---

**Generated:** November 7, 2025  
**Status:** âœ… robots.txt COMPLIANT with Google standards

